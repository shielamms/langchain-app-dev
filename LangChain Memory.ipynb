{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710edc08",
   "metadata": {},
   "source": [
    "In the previous notebook, Shakespeare was using LLMs with LangChain to help him translate English messages from customers into Shakespearean style. However, his previous method only allowed him to send disjoint messages to the LLM, since it could not keep track of the context of a convesation. He then set out to explore the concept of \"memory\" in LangChain so that he could converse with the LLM like a human being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e39468f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06e5278",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b302fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ddf2d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=model,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad44263b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['history', 'input'], output_parser=None, partial_variables={}, template='The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "938bde9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi! My name is Shakespeare\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Shakespeare! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Hi! My name is Shakespeare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf290df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi! My name is Shakespeare\n",
      "AI: Hello Shakespeare! It's nice to meet you. How can I assist you today?\n",
      "Human: What is a toaster?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A toaster is a small kitchen appliance used to toast bread slices. It typically consists of a metal or plastic housing with slots where you insert the bread. When you turn it on, the toaster heats up and toasts the bread by applying heat to both sides. Some toasters also have settings to adjust the level of toasting, allowing you to make your bread lighter or darker. Toasters are commonly used for making toast for breakfast or for making sandwiches.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='What is a toaster?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4bf50cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi! My name is Shakespeare\n",
      "AI: Hello Shakespeare! It's nice to meet you. How can I assist you today?\n",
      "Human: What is a toaster?\n",
      "AI: A toaster is a small kitchen appliance used to toast bread slices. It typically consists of a metal or plastic housing with slots where you insert the bread. When you turn it on, the toaster heats up and toasts the bread by applying heat to both sides. Some toasters also have settings to adjust the level of toasting, allowing you to make your bread lighter or darker. Toasters are commonly used for making toast for breakfast or for making sandwiches.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Shakespeare.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='What is my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bab6e914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: Hi! My name is Shakespeare\\nAI: Hello Shakespeare! It's nice to meet you. How can I assist you today?\\nHuman: What is a toaster?\\nAI: A toaster is a small kitchen appliance used to toast bread slices. It typically consists of a metal or plastic housing with slots where you insert the bread. When you turn it on, the toaster heats up and toasts the bread by applying heat to both sides. Some toasters also have settings to adjust the level of toasting, allowing you to make your bread lighter or darker. Toasters are commonly used for making toast for breakfast or for making sandwiches.\\nHuman: What is my name?\\nAI: Your name is Shakespeare.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ced2b2e",
   "metadata": {},
   "source": [
    "### Inject new memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1f5fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97ddc2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({'input': 'Hi!'},\n",
    "                    {'output': 'Whats up?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48c6f1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi!\n",
      "AI: Whats up?\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8e96241",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({'input': 'Not much. How about you?'},\n",
    "                    {'output': 'So-so. Not too bad, thanks.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae3898cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi!\n",
      "AI: Whats up?\n",
      "Human: Not much. How about you?\n",
      "AI: So-so. Not too bad, thanks.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fefa5a",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c8a1e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f87a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6b2403d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({'input': 'Hi!'},\n",
    "                    {'output': 'Hey whats up?'})\n",
    "memory.save_context({'input': 'Not much, so-so'},\n",
    "                    {'output': 'Cool cool cool'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e482b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, so-so\\nAI: Cool cool cool'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3505a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0.0)\n",
    "conversation = ConversationChain(\n",
    "    llm=model,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0fdf1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Not much, so-so\n",
      "AI: Cool cool cool\n",
      "Human: Hi! My name is Shakespeare\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Shakespeare! It's a pleasure to meet you. Is there anything specific you would like to talk about or any questions you have?\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Hi! My name is Shakespeare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6114262b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi! My name is Shakespeare\n",
      "AI: Hello Shakespeare! It's a pleasure to meet you. Is there anything specific you would like to talk about or any questions you have?\n",
      "Human: What is a toaster?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A toaster is a small kitchen appliance used to toast bread slices. It typically consists of a metal or plastic housing with slots where you insert the bread. When you turn it on, the toaster heats up and toasts the bread by applying radiant heat. Some toasters also have settings to adjust the level of toasting, allowing you to have your bread toasted to your preferred level of crispiness. Toasters are commonly used for making toast for breakfast or for making sandwiches.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='What is a toaster?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be3d3e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is a toaster?\n",
      "AI: A toaster is a small kitchen appliance used to toast bread slices. It typically consists of a metal or plastic housing with slots where you insert the bread. When you turn it on, the toaster heats up and toasts the bread by applying radiant heat. Some toasters also have settings to adjust the level of toasting, allowing you to have your bread toasted to your preferred level of crispiness. Toasters are commonly used for making toast for breakfast or for making sandwiches.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to personal information about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality.\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='What is my name?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae66294d",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "400cde37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4357113",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=model, max_token_limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b7fb1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43c14239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca4f146",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1bc3339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16c8db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryMemory(llm=model, max_token_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdbe7b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffaa6ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'The human greets the AI and the AI responds by asking what\\'s up. The human replies that they are not doing much, just hanging. The AI responds with a simple \"Cool.\" The human then asks about their schedule for the day. The AI informs them that they have a meeting at 8am with their product team, where they need to have their powerpoint presentation prepared. From 9am to 12pm, they have time to work on their LangChain project, which will be quick due to the power of LangChain. At noon, they have a lunch appointment with a customer who is driving from over an hour away to discuss the latest in AI. The AI advises the human to bring their laptop to show the latest LLM demo.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c26820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=model, \n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f96dd789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human greets the AI and the AI responds by asking what's up. The human replies that they are not doing much, just hanging. The AI responds with a simple \"Cool.\" The human then asks about their schedule for the day. The AI informs them that they have a meeting at 8am with their product team, where they need to have their powerpoint presentation prepared. From 9am to 12pm, they have time to work on their LangChain project, which will be quick due to the power of LangChain. At noon, they have a lunch appointment with a customer who is driving from over an hour away to discuss the latest in AI. The AI advises the human to bring their laptop to show the latest LLM demo.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"A good demo to show during your lunch appointment would be the latest Language Model for Language (LLM) demo. It showcases the power and capabilities of our AI technology in understanding and generating human-like text. You can demonstrate how LLM can generate coherent and contextually relevant responses to various prompts and questions. It's a great way to impress your customer and highlight the advancements we've made in natural language processing.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da88fba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
